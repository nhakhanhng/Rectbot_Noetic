# This Python file uses the following encoding: utf-8
"""autogenerated by genpy from rectbot_cv/PoseObject.msg. Do not edit."""
import codecs
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct

import geometry_msgs.msg
import rectbot_cv.msg
import sensor_msgs.msg
import std_msgs.msg
import vision_msgs.msg

class PoseObject(genpy.Message):
  _md5sum = "f36e3669b0713547250eac0a5f98a3b6"
  _type = "rectbot_cv/PoseObject"
  _has_header = False  # flag to mark the presence of a Header object
  _full_text = """vision_msgs/Detection2D detection
rectbot_cv/KeyPoint[] keypoints
================================================================================
MSG: vision_msgs/Detection2D
# Defines a 2D detection result.
#
# This is similar to a 2D classification, but includes position information,
#   allowing a classification result for a specific crop or image point to
#   to be located in the larger image.

Header header

# Class probabilities
ObjectHypothesisWithPose[] results

# 2D bounding box surrounding the object.
BoundingBox2D bbox

# The 2D data that generated these results (i.e. region proposal cropped out of
#   the image). Not required for all use cases, so it may be empty.
sensor_msgs/Image source_img

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')
# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
string frame_id

================================================================================
MSG: vision_msgs/ObjectHypothesisWithPose
# An object hypothesis that contains position information.

# The unique numeric ID of object detected. To get additional information about
#   this ID, such as its human-readable name, listeners should perform a lookup
#   in a metadata database. See vision_msgs/VisionInfo.msg for more detail.
int64 id

# The probability or confidence value of the detected object. By convention,
#   this value should lie in the range [0-1].
float64 score

# The 6D pose of the object hypothesis. This pose should be
#   defined as the pose of some fixed reference point on the object, such a
#   the geometric center of the bounding box or the center of mass of the
#   object.
# Note that this pose is not stamped; frame information can be defined by
#   parent messages.
# Also note that different classes predicted for the same input data may have
#   different predicted 6D poses.
geometry_msgs/PoseWithCovariance pose
================================================================================
MSG: geometry_msgs/PoseWithCovariance
# This represents a pose in free space with uncertainty.

Pose pose

# Row-major representation of the 6x6 covariance matrix
# The orientation parameters use a fixed-axis representation.
# In order, the parameters are:
# (x, y, z, rotation about X axis, rotation about Y axis, rotation about Z axis)
float64[36] covariance

================================================================================
MSG: geometry_msgs/Pose
# A representation of pose in free space, composed of position and orientation. 
Point position
Quaternion orientation

================================================================================
MSG: geometry_msgs/Point
# This contains the position of a point in free space
float64 x
float64 y
float64 z

================================================================================
MSG: geometry_msgs/Quaternion
# This represents an orientation in free space in quaternion form.

float64 x
float64 y
float64 z
float64 w

================================================================================
MSG: vision_msgs/BoundingBox2D
# A 2D bounding box that can be rotated about its center.
# All dimensions are in pixels, but represented using floating-point
#   values to allow sub-pixel precision. If an exact pixel crop is required
#   for a rotated bounding box, it can be calculated using Bresenham's line
#   algorithm.

# The 2D position (in pixels) and orientation of the bounding box center.
geometry_msgs/Pose2D center

# The size (in pixels) of the bounding box surrounding the object relative
#   to the pose of its center.
float64 size_x
float64 size_y

================================================================================
MSG: geometry_msgs/Pose2D
# Deprecated
# Please use the full 3D pose.

# In general our recommendation is to use a full 3D representation of everything and for 2D specific applications make the appropriate projections into the plane for their calculations but optimally will preserve the 3D information during processing.

# If we have parallel copies of 2D datatypes every UI and other pipeline will end up needing to have dual interfaces to plot everything. And you will end up with not being able to use 3D tools for 2D use cases even if they're completely valid, as you'd have to reimplement it with different inputs and outputs. It's not particularly hard to plot the 2D pose or compute the yaw error for the Pose message and there are already tools and libraries that can do this for you.


# This expresses a position and orientation on a 2D manifold.

float64 x
float64 y
float64 theta

================================================================================
MSG: sensor_msgs/Image
# This message contains an uncompressed image
# (0, 0) is at top-left corner of image
#

Header header        # Header timestamp should be acquisition time of image
                     # Header frame_id should be optical frame of camera
                     # origin of frame should be optical center of camera
                     # +x should point to the right in the image
                     # +y should point down in the image
                     # +z should point into to plane of the image
                     # If the frame_id here and the frame_id of the CameraInfo
                     # message associated with the image conflict
                     # the behavior is undefined

uint32 height         # image height, that is, number of rows
uint32 width          # image width, that is, number of columns

# The legal values for encoding are in file src/image_encodings.cpp
# If you want to standardize a new string format, join
# ros-users@lists.sourceforge.net and send an email proposing a new encoding.

string encoding       # Encoding of pixels -- channel meaning, ordering, size
                      # taken from the list of strings in include/sensor_msgs/image_encodings.h

uint8 is_bigendian    # is this data bigendian?
uint32 step           # Full row length in bytes
uint8[] data          # actual matrix data, size is (step * rows)

================================================================================
MSG: rectbot_cv/KeyPoint
std_msgs/Float32 x
std_msgs/Float32 y
std_msgs/Float32 score
================================================================================
MSG: std_msgs/Float32
float32 data"""
  __slots__ = ['detection','keypoints']
  _slot_types = ['vision_msgs/Detection2D','rectbot_cv/KeyPoint[]']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       detection,keypoints

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(PoseObject, self).__init__(*args, **kwds)
      # message fields cannot be None, assign default values for those that are
      if self.detection is None:
        self.detection = vision_msgs.msg.Detection2D()
      if self.keypoints is None:
        self.keypoints = []
    else:
      self.detection = vision_msgs.msg.Detection2D()
      self.keypoints = []

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      _x = self
      buff.write(_get_struct_3I().pack(_x.detection.header.seq, _x.detection.header.stamp.secs, _x.detection.header.stamp.nsecs))
      _x = self.detection.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.detection.results)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection.results:
        _x = val1
        buff.write(_get_struct_qd().pack(_x.id, _x.score))
        _v1 = val1.pose
        _v2 = _v1.pose
        _v3 = _v2.position
        _x = _v3
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v4 = _v2.orientation
        _x = _v4
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
        buff.write(_get_struct_36d().pack(*_v1.covariance))
      _x = self
      buff.write(_get_struct_5d3I().pack(_x.detection.bbox.center.x, _x.detection.bbox.center.y, _x.detection.bbox.center.theta, _x.detection.bbox.size_x, _x.detection.bbox.size_y, _x.detection.source_img.header.seq, _x.detection.source_img.header.stamp.secs, _x.detection.source_img.header.stamp.nsecs))
      _x = self.detection.source_img.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.detection.source_img.height, _x.detection.source_img.width))
      _x = self.detection.source_img.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.detection.source_img.is_bigendian, _x.detection.source_img.step))
      _x = self.detection.source_img.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.keypoints)
      buff.write(_struct_I.pack(length))
      for val1 in self.keypoints:
        _v5 = val1.x
        _x = _v5.data
        buff.write(_get_struct_f().pack(_x))
        _v6 = val1.y
        _x = _v6.data
        buff.write(_get_struct_f().pack(_x))
        _v7 = val1.score
        _x = _v7.data
        buff.write(_get_struct_f().pack(_x))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.detection is None:
        self.detection = vision_msgs.msg.Detection2D()
      if self.keypoints is None:
        self.keypoints = None
      end = 0
      _x = self
      start = end
      end += 12
      (_x.detection.header.seq, _x.detection.header.stamp.secs, _x.detection.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.detection.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection.results = []
      for i in range(0, length):
        val1 = vision_msgs.msg.ObjectHypothesisWithPose()
        _x = val1
        start = end
        end += 16
        (_x.id, _x.score,) = _get_struct_qd().unpack(str[start:end])
        _v8 = val1.pose
        _v9 = _v8.pose
        _v10 = _v9.position
        _x = _v10
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v11 = _v9.orientation
        _x = _v11
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        start = end
        end += 288
        _v8.covariance = _get_struct_36d().unpack(str[start:end])
        self.detection.results.append(val1)
      _x = self
      start = end
      end += 52
      (_x.detection.bbox.center.x, _x.detection.bbox.center.y, _x.detection.bbox.center.theta, _x.detection.bbox.size_x, _x.detection.bbox.size_y, _x.detection.source_img.header.seq, _x.detection.source_img.header.stamp.secs, _x.detection.source_img.header.stamp.nsecs,) = _get_struct_5d3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection.source_img.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.detection.source_img.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.detection.source_img.height, _x.detection.source_img.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection.source_img.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.detection.source_img.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.detection.source_img.is_bigendian, _x.detection.source_img.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.detection.source_img.data = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.keypoints = []
      for i in range(0, length):
        val1 = rectbot_cv.msg.KeyPoint()
        _v12 = val1.x
        start = end
        end += 4
        (_v12.data,) = _get_struct_f().unpack(str[start:end])
        _v13 = val1.y
        start = end
        end += 4
        (_v13.data,) = _get_struct_f().unpack(str[start:end])
        _v14 = val1.score
        start = end
        end += 4
        (_v14.data,) = _get_struct_f().unpack(str[start:end])
        self.keypoints.append(val1)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      _x = self
      buff.write(_get_struct_3I().pack(_x.detection.header.seq, _x.detection.header.stamp.secs, _x.detection.header.stamp.nsecs))
      _x = self.detection.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.detection.results)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection.results:
        _x = val1
        buff.write(_get_struct_qd().pack(_x.id, _x.score))
        _v15 = val1.pose
        _v16 = _v15.pose
        _v17 = _v16.position
        _x = _v17
        buff.write(_get_struct_3d().pack(_x.x, _x.y, _x.z))
        _v18 = _v16.orientation
        _x = _v18
        buff.write(_get_struct_4d().pack(_x.x, _x.y, _x.z, _x.w))
        buff.write(_v15.covariance.tostring())
      _x = self
      buff.write(_get_struct_5d3I().pack(_x.detection.bbox.center.x, _x.detection.bbox.center.y, _x.detection.bbox.center.theta, _x.detection.bbox.size_x, _x.detection.bbox.size_y, _x.detection.source_img.header.seq, _x.detection.source_img.header.stamp.secs, _x.detection.source_img.header.stamp.nsecs))
      _x = self.detection.source_img.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_2I().pack(_x.detection.source_img.height, _x.detection.source_img.width))
      _x = self.detection.source_img.encoding
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      _x = self
      buff.write(_get_struct_BI().pack(_x.detection.source_img.is_bigendian, _x.detection.source_img.step))
      _x = self.detection.source_img.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.Struct('<I%sB'%length).pack(length, *_x))
      else:
        buff.write(struct.Struct('<I%ss'%length).pack(length, _x))
      length = len(self.keypoints)
      buff.write(_struct_I.pack(length))
      for val1 in self.keypoints:
        _v19 = val1.x
        _x = _v19.data
        buff.write(_get_struct_f().pack(_x))
        _v20 = val1.y
        _x = _v20.data
        buff.write(_get_struct_f().pack(_x))
        _v21 = val1.score
        _x = _v21.data
        buff.write(_get_struct_f().pack(_x))
    except struct.error as se: self._check_types(struct.error("%s: '%s' when writing '%s'" % (type(se), str(se), str(locals().get('_x', self)))))
    except TypeError as te: self._check_types(ValueError("%s: '%s' when writing '%s'" % (type(te), str(te), str(locals().get('_x', self)))))

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    if python3:
      codecs.lookup_error("rosmsg").msg_type = self._type
    try:
      if self.detection is None:
        self.detection = vision_msgs.msg.Detection2D()
      if self.keypoints is None:
        self.keypoints = None
      end = 0
      _x = self
      start = end
      end += 12
      (_x.detection.header.seq, _x.detection.header.stamp.secs, _x.detection.header.stamp.nsecs,) = _get_struct_3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.detection.header.frame_id = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection.results = []
      for i in range(0, length):
        val1 = vision_msgs.msg.ObjectHypothesisWithPose()
        _x = val1
        start = end
        end += 16
        (_x.id, _x.score,) = _get_struct_qd().unpack(str[start:end])
        _v22 = val1.pose
        _v23 = _v22.pose
        _v24 = _v23.position
        _x = _v24
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _get_struct_3d().unpack(str[start:end])
        _v25 = _v23.orientation
        _x = _v25
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _get_struct_4d().unpack(str[start:end])
        start = end
        end += 288
        _v22.covariance = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=36)
        self.detection.results.append(val1)
      _x = self
      start = end
      end += 52
      (_x.detection.bbox.center.x, _x.detection.bbox.center.y, _x.detection.bbox.center.theta, _x.detection.bbox.size_x, _x.detection.bbox.size_y, _x.detection.source_img.header.seq, _x.detection.source_img.header.stamp.secs, _x.detection.source_img.header.stamp.nsecs,) = _get_struct_5d3I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection.source_img.header.frame_id = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.detection.source_img.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.detection.source_img.height, _x.detection.source_img.width,) = _get_struct_2I().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection.source_img.encoding = str[start:end].decode('utf-8', 'rosmsg')
      else:
        self.detection.source_img.encoding = str[start:end]
      _x = self
      start = end
      end += 5
      (_x.detection.source_img.is_bigendian, _x.detection.source_img.step,) = _get_struct_BI().unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.detection.source_img.data = str[start:end]
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.keypoints = []
      for i in range(0, length):
        val1 = rectbot_cv.msg.KeyPoint()
        _v26 = val1.x
        start = end
        end += 4
        (_v26.data,) = _get_struct_f().unpack(str[start:end])
        _v27 = val1.y
        start = end
        end += 4
        (_v27.data,) = _get_struct_f().unpack(str[start:end])
        _v28 = val1.score
        start = end
        end += 4
        (_v28.data,) = _get_struct_f().unpack(str[start:end])
        self.keypoints.append(val1)
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e)  # most likely buffer underfill

_struct_I = genpy.struct_I
def _get_struct_I():
    global _struct_I
    return _struct_I
_struct_2I = None
def _get_struct_2I():
    global _struct_2I
    if _struct_2I is None:
        _struct_2I = struct.Struct("<2I")
    return _struct_2I
_struct_36d = None
def _get_struct_36d():
    global _struct_36d
    if _struct_36d is None:
        _struct_36d = struct.Struct("<36d")
    return _struct_36d
_struct_3I = None
def _get_struct_3I():
    global _struct_3I
    if _struct_3I is None:
        _struct_3I = struct.Struct("<3I")
    return _struct_3I
_struct_3d = None
def _get_struct_3d():
    global _struct_3d
    if _struct_3d is None:
        _struct_3d = struct.Struct("<3d")
    return _struct_3d
_struct_4d = None
def _get_struct_4d():
    global _struct_4d
    if _struct_4d is None:
        _struct_4d = struct.Struct("<4d")
    return _struct_4d
_struct_5d3I = None
def _get_struct_5d3I():
    global _struct_5d3I
    if _struct_5d3I is None:
        _struct_5d3I = struct.Struct("<5d3I")
    return _struct_5d3I
_struct_BI = None
def _get_struct_BI():
    global _struct_BI
    if _struct_BI is None:
        _struct_BI = struct.Struct("<BI")
    return _struct_BI
_struct_f = None
def _get_struct_f():
    global _struct_f
    if _struct_f is None:
        _struct_f = struct.Struct("<f")
    return _struct_f
_struct_qd = None
def _get_struct_qd():
    global _struct_qd
    if _struct_qd is None:
        _struct_qd = struct.Struct("<qd")
    return _struct_qd
